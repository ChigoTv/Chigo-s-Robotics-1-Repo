# Gesture-Controlled Robot using Webots and Mediapipe

## ğŸ§  Project Overview

This project enables a differential-drive robot in Webots to be controlled via **hand gestures detected by a webcam**, using **MediaPipe** on one machine and **Webots simulation** on another â€” connected over a **Wi-Fi network using sockets**.

Gesture recognition is handled on a separate device (Laptop A), which sends commands like `fist`, `open`, `left`, and `right` to a Webots robot simulation running on another machine (Laptop B). The robot responds in real time to these commands.

---

## ğŸš€ How to Run the Project

### ğŸ”§ Requirements

- Webots installed on Laptop B
- Python 3.8â€“3.10 on both machines
- `mediapipe`, `opencv-python` installed on Laptop A
- Both machines connected to the **same network** (Wi-Fi or hotspot)

> âš ï¸ **IMPORTANT:** To access the dual-laptop gesture control functionality, both devices **must be on the same internet connection**.  
> It is highly recommended to use a **personal hotspot** if your Wi-Fi has firmware-based restrictions or peer-to-peer blockers.

### ğŸ“ File Structure

```
Robotics_Project2025/
â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ webots_controller_socket/
â”‚       â””â”€â”€ webots_controller_socket.py
â”œâ”€â”€ gesture_sender_client.py (run on Laptop A - Mac)
â”œâ”€â”€ ULTRA_DETAILED_README.md
```

### ğŸ–¥ On Laptop B (Windows â€“ Webots Host)

1. Open Webots and load the project world.
2. Ensure your robotâ€™s controller is set to:
   ```
   "webots_controller_socket"
   ```
3. Run simulation (press â–¶ï¸).
4. Confirm terminal output:
   ```
   ğŸŸ¢ Listening for gesture sender on port 5050...
   ```

### ğŸ’» On Laptop A (Mac â€“ Gesture Detection)

1. Open Terminal.
2. Navigate to project folder.
3. Update the IP address in `gesture_sender_client.py`:
   ```python
   SERVER_IP = "192.168.x.x"  # â† IP of Laptop B
   ```
4. Run:
   ```bash
   python3 gesture_sender_client.py
   ```

---

## ğŸ® Gesture Controls

| Gesture | Action            |
|---------|-------------------|
| âœŠ Fist  | Move Forward      |
| âœ‹ Open  | Move Backward     |
| â†©ï¸ Tilt Left | Turn Left         |
| â†ªï¸ Tilt Right | Turn Right        |

---

## âŒ¨ï¸ Failsafe Controls via WASD Keyboard Input

In addition to gesture recognition, the system includes a secondary **WASD keyboard control interface** as a fallback mechanism. This ensures that users can still operate the robot in case the gesture detection fails or becomes unresponsive due to lighting, occlusion, or webcam issues.

| Key | Action         |
|-----|----------------|
| W   | Move Forward   |
| A   | Turn Left      |
| S   | Move Backward  |
| D   | Turn Right     |

This dual-control strategy provides both **hands-free control** and **manual override**, improving the robustness and reliability of the system â€” particularly valuable during demos, testing, or industrial deployments where environmental factors may vary.

---

## ğŸ§ª Example Outputs

- **Console on Laptop B:**
  ```
  ğŸ“„ Gesture received: fist
  ğŸ“„ Gesture received: left
  ```

- **Webots Output:**
  Robot drives forward, turns, or stops in sync with gestures.

- **Camera Window on Mac:**
  - Live feed with detected gesture printed on screen.

---

## ğŸ§  Use Case in Industrial Robotics Integration

This gesture control system demonstrates a practical foundation for **industrial human-robot interaction**, particularly in:

- **Hazardous environments**: Gesture control enables operation of robotic systems in areas with toxic chemicals, heat, or radiation â€” where direct human control is dangerous.
- **Assembly lines**: Technicians can issue commands quickly without physical interfaces, increasing workflow efficiency.
- **Warehouse automation**: Supervisors can redirect or guide autonomous mobile robots using gestures, even with both hands occupied.
- **Remote operation**: In field or off-site facilities, gesture-controlled systems allow more intuitive long-distance control over maintenance or inspection robots.

This approach supports safer, more intuitive, and contactless robotic control â€” aligning with trends in **Industry 4.0 and smart manufacturing.**

---

## ğŸ“š References

- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html)
- [OpenCV](https://opencv.org/)
- [Webots Documentation](https://cyberbotics.com/doc/guide/index)

---

## ğŸ› ï¸ Future Improvements

- Add additional gestures (e.g., stop, turbo, spin)
- Implement voice control as a fallback
- Build a GUI toggle for switching between WASD and gesture mode
- Add ArUco markers for camera-based position feedback
- Package with Docker or installer for plug-and-play deployment

---

## ğŸ§° Step-by-Step Beginner Setup Instructions

This section walks through exactly how to prepare and run the system â€” perfect for someone unfamiliar with robotics or Webots.

### ğŸ”Œ Part 1: Setup on Laptop B (Robot Host â€“ Webots, Windows)

#### Step 1: Install Webots
- Download from [https://cyberbotics.com](https://cyberbotics.com)
- Install and run once to complete setup

#### Step 2: Load Project
- Place project files in a local folder
- Launch your `.wbt` file in Webots
- Set robotâ€™s controller to: `webots_controller_socket`

#### Step 3: Run Simulation
- Hit â–¶ï¸ in Webots
- Confirm socket listening message in console

### ğŸ“· Part 2: Setup on Laptop A (Gesture Detection â€“ Mac)

#### Step 1: Install Python 3.8â€“3.10
```bash
python3 --version
```

#### Step 2: Install Required Libraries
```bash
pip3 install mediapipe opencv-python
```

#### Step 3: Connect to Robot
Edit the IP of Laptop B in `gesture_sender_client.py`, then run:
```bash
python3 gesture_sender_client.py
```

---

## âœ… Testing Checklist

| Test | Expected Result |
|------|------------------|
| Webcam opens | Shows â€œGesture: ___â€ |
| Mac console | Shows â€œğŸ“¡ Connectedâ€¦â€ |
| Windows console | Shows â€œğŸ“„ Gesture receivedâ€¦â€ |
| Robot | Moves with gestures or WASD |

---
