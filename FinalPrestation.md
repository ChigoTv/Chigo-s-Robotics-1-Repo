# Gesture-Controlled Robot using Webots and Mediapipe

## ğŸ§  Project Overview

This project enables a differential-drive robot in Webots to be controlled via **hand gestures detected by a webcam**, using **MediaPipe** on one machine and **Webots simulation** on another â€” connected over a **Wi-Fi network using sockets**.

Gesture recognition is handled on a separate device (Laptop A), which sends commands like `fist`, `open`, `left`, and `right` to a Webots robot simulation running on another machine (Laptop B). The robot responds in real time to these commands.

---

## ğŸš€ How to Run the Project

### ğŸ”§ Requirements

- Webots installed on Laptop B
- Python 3.8â€“3.10 on both machines
- `mediapipe`, `opencv-python` installed on Laptop A
- Both machines connected to the **same network** (Wi-Fi or hotspot)

> âš ï¸ **IMPORTANT:** To access the dual-laptop gesture control functionality, both devices **must be on the same internet connection**.  
> It is highly recommended to use a **personal hotspot** if your Wi-Fi has firmware-based restrictions or peer-to-peer blockers.

### ğŸ“ File Structure

```
Robotics_Project2025/
â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ webots_controller_socket/
â”‚       â””â”€â”€ webots_controller_socket.py
â”œâ”€â”€ gesture_sender_client.py (run on Laptop A - Mac)
â”œâ”€â”€ README.md
```

### ğŸ–¥ On Laptop B (Windows â€“ Webots Host)

1. Open Webots and load the project world.
2. Ensure your robotâ€™s controller is set to:
   ```
   "webots_controller_socket"
   ```
3. Run simulation (press â–¶ï¸).
4. Confirm terminal output:
   ```
   ğŸŸ¢ Listening for gesture sender on port 5050...
   ```

### ğŸ’» On Laptop A (Mac â€“ Gesture Detection)

1. Open Terminal.
2. Navigate to project folder.
3. Update the IP address in `gesture_sender_client.py`:
   ```python
   SERVER_IP = "192.168.x.x"  # â† IP of Laptop B
   ```
4. Run:
   ```bash
   python3 gesture_sender_client.py
   ```

---

## ğŸ® Gesture Controls

| Gesture | Action            |
|---------|-------------------|
| âœŠ Fist  | Move Forward      |
| âœ‹ Open  | Move Backward     |
| â†©ï¸ Tilt Left | Turn Left         |
| â†ªï¸ Tilt Right | Turn Right        |

---

## ğŸ§ª Example Outputs

- **Console on Laptop B:**
  ```
  ğŸ“„ Gesture received: fist
  ğŸ“„ Gesture received: left
  ```

- **Webots Output:**
  Robot drives forward, turns, or stops in sync with gestures.

- **Camera Window on Mac:**
  - Live feed with detected gesture printed on screen.

---

## ğŸ§  Use Case in Industrial Robotics Integration

This gesture control system demonstrates a practical foundation for **industrial human-robot interaction**, particularly in:

- **Hazardous environments**: Gesture control enables operation of robotic systems in areas with toxic chemicals, heat, or radiation â€” where direct human control is dangerous.
- **Assembly lines**: Technicians can issue commands quickly without physical interfaces, increasing workflow efficiency.
- **Warehouse automation**: Supervisors can redirect or guide autonomous mobile robots using gestures, even with both hands occupied.
- **Remote operation**: In field or off-site facilities, gesture-controlled systems allow more intuitive long-distance control over maintenance or inspection robots.

This approach supports safer, more intuitive, and contactless robotic control â€” aligning with trends in **Industry 4.0 and smart manufacturing.**

---
## âŒ¨ï¸ Failsafe Controls via WASD Keyboard Input

In addition to gesture recognition, the system includes a secondary **WASD keyboard control interface** as a fallback mechanism. This ensures that users can still operate the robot in case the gesture detection fails or becomes unresponsive due to lighting, occlusion, or webcam issues.

| Key | Action         |
|-----|----------------|
| W   | Move Forward   |
| A   | Turn Left      |
| S   | Move Backward  |
| D   | Turn Right     |

This dual-control strategy provides both **hands-free control** and **manual override**, improving the robustness and reliability of the system â€” particularly valuable during demos, testing, or industrial deployments where environmental factors may vary.

---

## ğŸ“š References

- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html) â€“ for gesture detection
- [OpenCV](https://opencv.org/) â€“ for webcam image processing
- [Webots Documentation](https://cyberbotics.com/doc/guide/index) â€“ for robot simulation

---

## ğŸ› ï¸ Future Improvements

- Add additional gestures (e.g., stop, turbo, spin).
- Implement voice control as a fallback.
- Build a GUI toggle for switching between WASD and gesture mode.
- Add ArUco markers for camera-based position feedback.
- Package with Docker or installer for plug-and-play deployment.

---

## ğŸ‘¥ Authors

- Chigozie Eke (Lead Developer, Robotics Simulation Integration)
- Om Samel (Lead Gesture Control Integrator)


---

