# Gesture-Controlled Robot using Webots and Mediapipe

## ðŸ§  Project Overview

This project enables a differential-drive robot in Webots to be controlled via **hand gestures detected by a webcam**, using **MediaPipe** on one machine and **Webots simulation** on another â€” connected over a **Wi-Fi network using sockets**.

Gesture recognition is handled on a separate device (Laptop A), which sends commands like `fist`, `open`, `left`, and `right` to a Webots robot simulation running on another machine (Laptop B). The robot responds in real time to these commands.

---

## ðŸš€ How to Run the Project

### ðŸ”§ Requirements

- Webots installed on Laptop B
- Python 3.8â€“3.10 on both machines
- `mediapipe`, `opencv-python` installed on Laptop A
- Both machines connected to the **same network** (Wi-Fi or hotspot)

### ðŸ“ File Structure

```
Robotics_Project2025/
â”œâ”€â”€ controllers/
â”‚   â””â”€â”€ webots_controller_socket/
â”‚       â””â”€â”€ webots_controller_socket.py
â”œâ”€â”€ gesture_sender_client.py (run on Laptop A - Mac)
â”œâ”€â”€ README.md
```

### ðŸ–¥ On Laptop B (Windows â€“ Webots Host)

1. Open Webots and load the project world.
2. Ensure your robotâ€™s controller is set to:
   ```
   "webots_controller_socket"
   ```
3. Run simulation (press â–¶ï¸).
4. Confirm terminal output:
   ```
   ðŸŸ¢ Listening for gesture sender on port 5050...
   ```

### ðŸ’» On Laptop A (Mac â€“ Gesture Detection)

1. Open Terminal.
2. Navigate to project folder.
3. Update the IP address in `gesture_sender_client.py`:
   ```python
   SERVER_IP = "192.168.x.x"  # â† IP of Laptop B
   ```
4. Run:
   ```bash
   python3 gesture_sender_client.py
   ```

---

## ðŸŽ® Gesture Controls

| Gesture | Action            |
|---------|-------------------|
| âœŠ Fist  | Move Forward      |
| âœ‹ Open  | Move Backward     |
| â†©ï¸ Tilt Left | Turn Left         |
| â†ªï¸ Tilt Right | Turn Right        |

---

## ðŸ§ª Example Outputs

- **Console on Laptop B:**
  ```
  ðŸ“„ Gesture received: fist
  ðŸ“„ Gesture received: left
  ```

- **Webots Output:**
  Robot drives forward, turns, or stops in sync with gestures.

- **Camera Window on Mac:**
  - Live feed with detected gesture printed on screen.

---

## ðŸ“š References

- [MediaPipe Hands](https://google.github.io/mediapipe/solutions/hands.html) â€“ for gesture detection
- [OpenCV](https://opencv.org/) â€“ for webcam image processing
- [Webots Documentation](https://cyberbotics.com/doc/guide/index) â€“ for robot simulation

---

## ðŸ› ï¸ Future Improvements

- Add additional gestures (e.g., stop, turbo, spin).
- Implement voice control as a fallback.
- Build a GUI toggle for switching between WASD and gesture mode.
- Add ArUco markers for camera-based position feedback.
- Package with Docker or installer for plug-and-play deployment.

---

## ðŸ” Peer Review Section

- This documentation was reviewed by: **[Team _______________]**
- We have also reviewed the documentation of: **[Team _______________]**

**Reviewer Notes:**
> [Your peer review team can insert constructive feedback or suggestions here.]

---

## ðŸ‘¥ Authors

- Chigozie Eke (Lead Developer, Gesture Control & Robotics Integration)
- [Team Member Name] â€“ [Role, if applicable]